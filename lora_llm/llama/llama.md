# todo

Public release of LLaMA (Large Language Model Meta AI), an advanced foundational large language model aimed at assisting researchers in advancing their work in the field of AI. By providing smaller yet high-performing models like LLaMA, we empower researchers in the community who may have limited access to extensive infrastructure, thereby democratizing access in this rapidly evolving and significant domain.

Training smaller foundational models, such as LLaMA, holds immense value in the realm of large language models as it demands significantly fewer computational resources and facilitates the testing of new approaches, validation of others' work, and exploration of novel use cases. Foundation models are trained on a vast corpus of unlabeled data, rendering them ideal for fine-tuning across a wide range of tasks. LLaMA is made available in various sizes (7B, 13B, 33B, and 65B parameters), and we are also sharing a comprehensive LLaMA model card that provides insights into the model's construction, aligning with our commitment to Responsible AI practices.

Over the past year, large language models—NLP systems equipped with billions of parameters—have demonstrated remarkable capabilities, including generating creative text, solving mathematical theorems, predicting protein structures, answering reading comprehension questions, and more. They exemplify the substantial potential benefits that AI can deliver at scale, benefiting billions of people.

Despite the recent advancements in large language models, full research access to these models remains limited due to the extensive resources required for training and running such large-scale models. This restricted access hinders researchers' ability to comprehend the mechanisms and underlying principles of these models, impeding progress in enhancing their robustness and addressing known issues like bias, toxicity, and the generation of misinformation.

Smaller models trained on a larger number of tokens, which are fragments of words, offer greater flexibility for retraining and fine-tuning for specific product use cases. We trained LLaMA 65B and LLaMA 33B using 1.4 trillion tokens, while our smallest model, LLaMA 7B, is trained on one trillion tokens.

Similar to other large language models, LLaMA operates by taking a sequence of words as input and recursively generates text by predicting the next word. For model training, we selected text from the top 20 languages with the highest number of speakers, with a focus on those using Latin and Cyrillic alphabets.

Addressing risks such as bias, toxic comments, and hallucinations in large language models necessitates further research. LLaMA encounters these challenges, like other models. As a foundational model, LLaMA is designed to be versatile and applicable to various use cases, as opposed to fine-tuned models that cater to specific tasks. By sharing the code for LLaMA, we aim to facilitate the testing of new approaches to mitigate or eliminate these issues in large language models. Additionally, we provide a series of evaluations in the paper that assess model biases and toxicity on benchmark datasets, highlighting the model's limitations and promoting further research in this critical area.

To maintain integrity and prevent misuse, we are releasing our model under a noncommercial license primarily focused on research purposes. Access to the model will be granted on a case-by-case basis to academic researchers, individuals affiliated with government organizations, civil society, academia, and industry research laboratories worldwide. Those interested in accessing the model can find the application link in our research paper.

We strongly believe that the entire AI community—academic researchers, civil society, policymakers, and industry stakeholders—must collaborate to establish clear guidelines regarding responsible AI in general, and responsible large language models in particular. We eagerly anticipate witnessing the knowledge and advancements the community can acquire and ultimately develop using LLaMA.
